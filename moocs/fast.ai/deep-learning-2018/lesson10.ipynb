{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 10\n",
    "\n",
    "## 00:00:14 - Review of last week\n",
    "\n",
    "* Last week: lots of people struggling with the material from last week.\n",
    "  * By Lesson 14, you'll have a second go at Object Detection.\n",
    "* Multiple objects is similar to the single bounding box problem, except we have to solve the \"matching problems\"\n",
    "  * Create far more activations than ground truth bounding boxes, and match each ground truth object to a set of the activations.\n",
    "* If you're stuck: revisit Lesson 8.\n",
    "  \n",
    "## 00:02:42 - Multiple objects revision\n",
    "\n",
    "* More activations.\n",
    "* Took advantage of convolutional natural of network to try to have activiations that had a receptive field that was similar to ground truth objects we're predicting.\n",
    "  * [Chloe Sultan](http://forums.fast.ai/t/part-2-lesson-9-wiki/14028/375) mapped out the size of the grids as the network downsamples using stride 2 convolutions.\n",
    "  \n",
    "<img src=\"http://forums.fast.ai/uploads/default/optimized/2X/a/a7942de9d5bf6c3afe50e10d55116c6c7fb5b721_1_669x500.png\" width=\"700px\">\n",
    "\n",
    "* How did she calculate the numbers?\n",
    "  * Could use PDB set trace to view the output at each step of the network.\n",
    "* Talked about increasing K: number of activations using different zooms and sizes.\n",
    "* Got down to a small num of bounding boxes using NMS.\n",
    "  * A paper has come out to try to calculate an end-to-end network (not using NMS)\n",
    "\n",
    "\n",
    "## 00:07:04 - Reading papers\n",
    "\n",
    "* Not enough people reading papers in study group: papers are the \"real ground truth\".\n",
    "  * ``SSD_MultiHead.forward`` is not doing the same thing as the SSD paper: the paper may have a better version.\n",
    "  * Uses a smaller k but a lot more smaller grids.\n",
    "* Useful to map code and equations together:\n",
    "\n",
    "<img src=\"https://i.gyazo.com/84dc304d3d8eab72b6fcbc1895424aa5.gif\" width=\"700px\">\n",
    "\n",
    "  * Some people are code people who learn the math from the code and vice versa.\n",
    "  \n",
    "## 00:10:08 - Math notation\n",
    "\n",
    "* Math notation can be hard to lookup.\n",
    "* [List of mathematical symbols](https://en.wikipedia.org/wiki/List_of_mathematical_symbols) Wikipedia article is a useful reference.\n",
    "* Nobody learns all of math in one go: even top researchers need to research math symbols.\n",
    "\n",
    "## 00:11:17 - Recreating results in papers\n",
    "\n",
    "* Key figure from retina loss figure was created in Excel by Sarada Lee from the forums.\n",
    "\n",
    "\n",
    "## 00:14:12 - NLP\n",
    "\n",
    "* Seen the idea of taking a pretrained model, removing the top layer and getting it to do something similar.\n",
    " * Want to see if that idea applies to NLP.\n",
    "* Next lesson: combine NLP and computer vision.\n",
    "  * learn to find word structures from images (image captioning)\n",
    "  * learn to find images from word structures\n",
    "\n",
    "## 00:18:56 - torchtext to fastai.text\n",
    "\n",
    "* torchtext has a number of limitations:\n",
    "  * quite slow\n",
    "    * doesn't do parallel processing.\n",
    "    * doesn't cache results.\n",
    "  * hard to do simple things like multi label problems.\n",
    "* `fastai.text` is a replacement for `fastai.nlp`\n",
    "\n",
    "## 00:20:30 - IMDB revisited\n",
    "\n",
    "* Dataset of movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%install_ext` not found.\n"
     ]
    }
   ],
   "source": [
    "%install_ext https://raw.githubusercontent.com/SiggyF/notebooks/master/pep8_magic.py\n",
    "\n",
    "from fastai.fastai.text import *\n",
    "import html\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH=Path('./data/aclImdb/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-27 15:23:10--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘data/aclImdb_v1.tar.gz.1’\n",
      "\n",
      "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  11.0MB/s    in 6.5s    \n",
      "\n",
      "2018-07-27 15:23:17 (12.4 MB/s) - ‘data/aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz  --directory-prefix=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf data/aclImdb_v1.tar.gz.1 -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEGINNING_OF_SENTENCE_TAG = 'xbos'  # beginning of sentence tag\n",
    "DATAFIELD_TAG = 'xfld'  # data field tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLAS_PATH = Path('data/imdb_clas/')\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LM_PATH = Path('data/imdb_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSES = ['neg', 'pos', 'unsup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(path):\n",
    "    texts, labels = [], []\n",
    "    for idx, label in enumerate(CLASSES):\n",
    "        for fname in (path / label).glob('*.*'):\n",
    "            texts.append(fname.open('r').read())\n",
    "            labels.append(idx)\n",
    "\n",
    "    return np.array(texts), np.array(labels)\n",
    "            \n",
    "trn_texts, trn_labels = get_texts(PATH / 'train')\n",
    "val_texts, val_labels = get_texts(PATH / 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 25000)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Approach above is much easier than the convoluted torch text method - reading text is not that hard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names = ['labels', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "train_idx = np.random.permutation(len(trn_texts))\n",
    "val_idx = np.random.permutation(len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = trn_texts[train_idx]\n",
    "val_texts = val_texts[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = trn_labels[train_idx]\n",
    "val_labels = val_labels[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I bought this DVD for $2.00 at the local variety warehouse. The creepy clown cover and quote \"he\\'s not clowning around\"took my eye with a hope of either a Horror/slasher or possibly a b grade movie that might have some laughs.<br /><br />Man was i mistaken. This movie might be OK to see if you had smoked some wicked herb or taken some acid, though because i hadnt it just made me angry.<br /><br />The story/plot was not original and the constant use of similar sounding riffs to the john carpenter halloween theme and the ëxcorcist theme quickly became annoying.<br /><br />Alice witnessed the death of her son or did she? Was it the good clown,bad clown an evil serial killer or herself? I don\\'t know if this film was SUPPOSED to be open for interpretation if this was the writer/directors master plan... i don\\'t think it was.<br /><br />maybe i am not really here typing this review and i am secretly in some mental hospital thinking about writing this review?.<br /><br />Overall this film blows.<br /><br />1/10'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00:25:50 - Classification path vs language model path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Classification model requires labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>I bought this DVD for $2.00 at the local varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1st watched 4/29/2007 - 4 out of 10(Dir-Mick G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Election is a Chinese mob movie, or triads in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>I will ignore the obviously superior films by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>I went into this film with no expectations. St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       2  I bought this DVD for $2.00 at the local varie...\n",
       "1       0  1st watched 4/29/2007 - 4 out of 10(Dir-Mick G...\n",
       "2       1  Election is a Chinese mob movie, or triads in ...\n",
       "3       2  I will ignore the obviously superior films by ...\n",
       "4       2  I went into this film with no expectations. St..."
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame({'text': train_texts, 'labels': train_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text': val_texts, 'labels': val_labels}, columns=col_names)\n",
    "\n",
    "df_train[df_train['labels'] != 2].to_csv(CLAS_PATH / 'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH / 'test.csv', header=False, index=False)\n",
    "\n",
    "(CLAS_PATH / 'classes.txt').open('w').writelines(f'{o}\\n' for o in CLASSES)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Language model has no labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I bought this DVD for $2.00 at the local varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1st watched 4/29/2007 - 4 out of 10(Dir-Mick G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Election is a Chinese mob movie, or triads in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I will ignore the obviously superior films by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I went into this film with no expectations. St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       0  I bought this DVD for $2.00 at the local varie...\n",
       "1       0  1st watched 4/29/2007 - 4 out of 10(Dir-Mick G...\n",
       "2       0  Election is a Chinese mob movie, or triads in ...\n",
       "3       0  I will ignore the obviously superior films by ...\n",
       "4       0  I went into this film with no expectations. St..."
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame({'text': train_texts, 'labels': [0] * len(train_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text': val_texts, 'labels': [0] * len(val_labels)}, columns=col_names)\n",
    "\n",
    "df_train[df_train['labels'] != 2].to_csv(CLAS_PATH / 'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH / 'test.csv', header=False, index=False)\n",
    "\n",
    "(CLAS_PATH / 'classes.txt').open('w').writelines(f'{o}\\n' for o in CLASSES)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can create validation set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts = sklearn.model_selection.train_test_split(\n",
    "    np.concatenate([train_texts, val_texts]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunk_size = 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re1 = re.compile(r' +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = (x\n",
    "        .replace('#39;', \"'\")\n",
    "        .replace('amp;', '&')\n",
    "        .replace('#146;', \"'\")\n",
    "        .replace('nbsp;', ' ')\n",
    "        .replace('#36;', '$')\n",
    "        .replace('\\\\n', \"\\n\")\n",
    "        .replace('quot;', \"'\")\n",
    "        .replace('<br />', \"\\n\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace('<unk>', 'u_n')\n",
    "        .replace(' @.@ ', '.')\n",
    "        .replace(' @-@ ', '-')\n",
    "        .replace('\\\\', ' \\\\ '))\n",
    "\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, num_labels=1):\n",
    "    labels = df.iloc[:, range(num_labels)].values.astype(np.int64)\n",
    "    texts = f'\\n{BEGINNING_OF_SENTENCE_TAG} {DATAFIELD_TAG} 1' + df[num_labels].astype(str)\n",
    "    for i in range(num_labels + 1, len(df.columns)):\n",
    "        texts += f' {DATAFIELD_TAG} [i - num_labels]' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "    \n",
    "    core_partitions = partition_by_cores(texts)\n",
    "    tok = Tokenizer().proc_all_mp(core_partitions)\n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 57.9MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(LM_PATH / 'train.csv', header=None, chunksize=chunk_size)\n",
    "df_val = pd.read_csv(LM_PATH / 'test.csv', header=None, chunksize=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tok_trn, train_labels = get_all(df_train, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(LM_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 686043),\n",
       " ('.', 564563),\n",
       " (',', 562529),\n",
       " ('and', 336037),\n",
       " ('a', 331366),\n",
       " ('of', 299003),\n",
       " ('to', 276187),\n",
       " ('is', 225266),\n",
       " ('it', 193359),\n",
       " ('in', 192089),\n",
       " ('i', 162280),\n",
       " ('that', 149386),\n",
       " ('this', 146216),\n",
       " ('\"', 134061),\n",
       " (\"'s\", 126735),\n",
       " ('-', 107354),\n",
       " ('was', 102382),\n",
       " ('\\n\\n', 102266),\n",
       " ('as', 94208),\n",
       " ('with', 91086),\n",
       " ('for', 90453),\n",
       " ('movie', 89957),\n",
       " ('but', 86291),\n",
       " ('film', 82097),\n",
       " (')', 70829)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o, c in freq.most_common(max_vocab) if c > min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
